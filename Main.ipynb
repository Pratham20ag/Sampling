{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a1dc7e25",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd;\n",
    "from imblearn.over_sampling import SMOTE \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "58fc07c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('Creditcard_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "42aeac6b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.62</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.69</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.99</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Time        V1        V2        V3        V4        V5        V6        V7  \\\n",
       "0     0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388  0.239599   \n",
       "1     0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361 -0.078803   \n",
       "2     1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499  0.791461   \n",
       "3     1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203  0.237609   \n",
       "4     2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921  0.592941   \n",
       "\n",
       "         V8        V9  ...       V21       V22       V23       V24       V25  \\\n",
       "0  0.098698  0.363787  ... -0.018307  0.277838 -0.110474  0.066928  0.128539   \n",
       "1  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288 -0.339846  0.167170   \n",
       "2  0.247676 -1.514654  ...  0.247998  0.771679  0.909412 -0.689281 -0.327642   \n",
       "3  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321 -1.175575  0.647376   \n",
       "4 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458  0.141267 -0.206010   \n",
       "\n",
       "        V26       V27       V28  Amount  Class  \n",
       "0 -0.189115  0.133558 -0.021053  149.62      0  \n",
       "1  0.125895 -0.008983  0.014724    2.69      1  \n",
       "2 -0.139097 -0.055353 -0.059752  378.66      0  \n",
       "3 -0.221929  0.062723  0.061458  123.50      0  \n",
       "4  0.502292  0.219422  0.215153   69.99      0  \n",
       "\n",
       "[5 rows x 31 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8b4312a4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1      9\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f1db9c7",
   "metadata": {},
   "source": [
    "Highly Imbalanced Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ff79ad5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop('Class',axis = 1)\n",
    "Y = df['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "3af5a14e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smote = SMOTE(random_state = 42)\n",
    "X_resampled,Y_resampled = smote.fit_resample(X,Y)\n",
    "Y_resampled.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c5bfcd03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Time</th>\n",
       "      <th>V1</th>\n",
       "      <th>V2</th>\n",
       "      <th>V3</th>\n",
       "      <th>V4</th>\n",
       "      <th>V5</th>\n",
       "      <th>V6</th>\n",
       "      <th>V7</th>\n",
       "      <th>V8</th>\n",
       "      <th>V9</th>\n",
       "      <th>...</th>\n",
       "      <th>V21</th>\n",
       "      <th>V22</th>\n",
       "      <th>V23</th>\n",
       "      <th>V24</th>\n",
       "      <th>V25</th>\n",
       "      <th>V26</th>\n",
       "      <th>V27</th>\n",
       "      <th>V28</th>\n",
       "      <th>Amount</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.359807</td>\n",
       "      <td>-0.072781</td>\n",
       "      <td>2.536347</td>\n",
       "      <td>1.378155</td>\n",
       "      <td>-0.338321</td>\n",
       "      <td>0.462388</td>\n",
       "      <td>0.239599</td>\n",
       "      <td>0.098698</td>\n",
       "      <td>0.363787</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.018307</td>\n",
       "      <td>0.277838</td>\n",
       "      <td>-0.110474</td>\n",
       "      <td>0.066928</td>\n",
       "      <td>0.128539</td>\n",
       "      <td>-0.189115</td>\n",
       "      <td>0.133558</td>\n",
       "      <td>-0.021053</td>\n",
       "      <td>149.620000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1.191857</td>\n",
       "      <td>0.266151</td>\n",
       "      <td>0.166480</td>\n",
       "      <td>0.448154</td>\n",
       "      <td>0.060018</td>\n",
       "      <td>-0.082361</td>\n",
       "      <td>-0.078803</td>\n",
       "      <td>0.085102</td>\n",
       "      <td>-0.255425</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.225775</td>\n",
       "      <td>-0.638672</td>\n",
       "      <td>0.101288</td>\n",
       "      <td>-0.339846</td>\n",
       "      <td>0.167170</td>\n",
       "      <td>0.125895</td>\n",
       "      <td>-0.008983</td>\n",
       "      <td>0.014724</td>\n",
       "      <td>2.690000</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.358354</td>\n",
       "      <td>-1.340163</td>\n",
       "      <td>1.773209</td>\n",
       "      <td>0.379780</td>\n",
       "      <td>-0.503198</td>\n",
       "      <td>1.800499</td>\n",
       "      <td>0.791461</td>\n",
       "      <td>0.247676</td>\n",
       "      <td>-1.514654</td>\n",
       "      <td>...</td>\n",
       "      <td>0.247998</td>\n",
       "      <td>0.771679</td>\n",
       "      <td>0.909412</td>\n",
       "      <td>-0.689281</td>\n",
       "      <td>-0.327642</td>\n",
       "      <td>-0.139097</td>\n",
       "      <td>-0.055353</td>\n",
       "      <td>-0.059752</td>\n",
       "      <td>378.660000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>-0.966272</td>\n",
       "      <td>-0.185226</td>\n",
       "      <td>1.792993</td>\n",
       "      <td>-0.863291</td>\n",
       "      <td>-0.010309</td>\n",
       "      <td>1.247203</td>\n",
       "      <td>0.237609</td>\n",
       "      <td>0.377436</td>\n",
       "      <td>-1.387024</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.108300</td>\n",
       "      <td>0.005274</td>\n",
       "      <td>-0.190321</td>\n",
       "      <td>-1.175575</td>\n",
       "      <td>0.647376</td>\n",
       "      <td>-0.221929</td>\n",
       "      <td>0.062723</td>\n",
       "      <td>0.061458</td>\n",
       "      <td>123.500000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.158233</td>\n",
       "      <td>0.877737</td>\n",
       "      <td>1.548718</td>\n",
       "      <td>0.403034</td>\n",
       "      <td>-0.407193</td>\n",
       "      <td>0.095921</td>\n",
       "      <td>0.592941</td>\n",
       "      <td>-0.270533</td>\n",
       "      <td>0.817739</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.009431</td>\n",
       "      <td>0.798278</td>\n",
       "      <td>-0.137458</td>\n",
       "      <td>0.141267</td>\n",
       "      <td>-0.206010</td>\n",
       "      <td>0.502292</td>\n",
       "      <td>0.219422</td>\n",
       "      <td>0.215153</td>\n",
       "      <td>69.990000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>233</td>\n",
       "      <td>-0.143424</td>\n",
       "      <td>0.517932</td>\n",
       "      <td>0.731111</td>\n",
       "      <td>0.129628</td>\n",
       "      <td>0.854012</td>\n",
       "      <td>0.001878</td>\n",
       "      <td>0.422518</td>\n",
       "      <td>0.075371</td>\n",
       "      <td>-0.127180</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.086502</td>\n",
       "      <td>-0.238275</td>\n",
       "      <td>0.062436</td>\n",
       "      <td>-0.985098</td>\n",
       "      <td>-1.003529</td>\n",
       "      <td>-0.039215</td>\n",
       "      <td>0.158937</td>\n",
       "      <td>0.153083</td>\n",
       "      <td>0.992166</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1522</th>\n",
       "      <td>288</td>\n",
       "      <td>-0.314860</td>\n",
       "      <td>0.491771</td>\n",
       "      <td>0.951783</td>\n",
       "      <td>0.141217</td>\n",
       "      <td>0.878564</td>\n",
       "      <td>-0.195386</td>\n",
       "      <td>0.522255</td>\n",
       "      <td>0.024692</td>\n",
       "      <td>-0.130443</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.053105</td>\n",
       "      <td>-0.124739</td>\n",
       "      <td>-0.007566</td>\n",
       "      <td>-0.685670</td>\n",
       "      <td>-0.698822</td>\n",
       "      <td>-0.129806</td>\n",
       "      <td>0.101392</td>\n",
       "      <td>0.092159</td>\n",
       "      <td>0.993877</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1523</th>\n",
       "      <td>465</td>\n",
       "      <td>-2.161259</td>\n",
       "      <td>-0.202359</td>\n",
       "      <td>0.365042</td>\n",
       "      <td>2.613566</td>\n",
       "      <td>0.923353</td>\n",
       "      <td>-0.447669</td>\n",
       "      <td>-2.330450</td>\n",
       "      <td>1.099415</td>\n",
       "      <td>-0.963817</td>\n",
       "      <td>...</td>\n",
       "      <td>0.471321</td>\n",
       "      <td>0.560975</td>\n",
       "      <td>-0.095592</td>\n",
       "      <td>-0.250085</td>\n",
       "      <td>-0.083285</td>\n",
       "      <td>0.508771</td>\n",
       "      <td>0.074280</td>\n",
       "      <td>-0.156735</td>\n",
       "      <td>0.726598</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1524</th>\n",
       "      <td>516</td>\n",
       "      <td>-2.181198</td>\n",
       "      <td>-1.036044</td>\n",
       "      <td>1.153616</td>\n",
       "      <td>0.342333</td>\n",
       "      <td>1.069585</td>\n",
       "      <td>-0.553986</td>\n",
       "      <td>0.288244</td>\n",
       "      <td>0.069938</td>\n",
       "      <td>-0.076396</td>\n",
       "      <td>...</td>\n",
       "      <td>0.105787</td>\n",
       "      <td>0.020804</td>\n",
       "      <td>0.293645</td>\n",
       "      <td>-0.256581</td>\n",
       "      <td>-0.126499</td>\n",
       "      <td>0.109506</td>\n",
       "      <td>-0.313804</td>\n",
       "      <td>-0.241336</td>\n",
       "      <td>180.086978</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1525</th>\n",
       "      <td>365</td>\n",
       "      <td>-1.073464</td>\n",
       "      <td>-1.133695</td>\n",
       "      <td>1.566331</td>\n",
       "      <td>0.681840</td>\n",
       "      <td>1.729351</td>\n",
       "      <td>0.441039</td>\n",
       "      <td>-1.034480</td>\n",
       "      <td>0.498312</td>\n",
       "      <td>0.475220</td>\n",
       "      <td>...</td>\n",
       "      <td>0.176062</td>\n",
       "      <td>0.490331</td>\n",
       "      <td>0.232206</td>\n",
       "      <td>-1.083672</td>\n",
       "      <td>-0.742202</td>\n",
       "      <td>0.509854</td>\n",
       "      <td>0.034676</td>\n",
       "      <td>0.008290</td>\n",
       "      <td>1.272031</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1526 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Time        V1        V2        V3        V4        V5        V6  \\\n",
       "0        0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
       "1        0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
       "2        1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
       "3        1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
       "4        2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
       "...    ...       ...       ...       ...       ...       ...       ...   \n",
       "1521   233 -0.143424  0.517932  0.731111  0.129628  0.854012  0.001878   \n",
       "1522   288 -0.314860  0.491771  0.951783  0.141217  0.878564 -0.195386   \n",
       "1523   465 -2.161259 -0.202359  0.365042  2.613566  0.923353 -0.447669   \n",
       "1524   516 -2.181198 -1.036044  1.153616  0.342333  1.069585 -0.553986   \n",
       "1525   365 -1.073464 -1.133695  1.566331  0.681840  1.729351  0.441039   \n",
       "\n",
       "            V7        V8        V9  ...       V21       V22       V23  \\\n",
       "0     0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
       "1    -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
       "2     0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
       "3     0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
       "4     0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
       "...        ...       ...       ...  ...       ...       ...       ...   \n",
       "1521  0.422518  0.075371 -0.127180  ... -0.086502 -0.238275  0.062436   \n",
       "1522  0.522255  0.024692 -0.130443  ... -0.053105 -0.124739 -0.007566   \n",
       "1523 -2.330450  1.099415 -0.963817  ...  0.471321  0.560975 -0.095592   \n",
       "1524  0.288244  0.069938 -0.076396  ...  0.105787  0.020804  0.293645   \n",
       "1525 -1.034480  0.498312  0.475220  ...  0.176062  0.490331  0.232206   \n",
       "\n",
       "           V24       V25       V26       V27       V28      Amount  Class  \n",
       "0     0.066928  0.128539 -0.189115  0.133558 -0.021053  149.620000      0  \n",
       "1    -0.339846  0.167170  0.125895 -0.008983  0.014724    2.690000      1  \n",
       "2    -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.660000      0  \n",
       "3    -1.175575  0.647376 -0.221929  0.062723  0.061458  123.500000      0  \n",
       "4     0.141267 -0.206010  0.502292  0.219422  0.215153   69.990000      0  \n",
       "...        ...       ...       ...       ...       ...         ...    ...  \n",
       "1521 -0.985098 -1.003529 -0.039215  0.158937  0.153083    0.992166      1  \n",
       "1522 -0.685670 -0.698822 -0.129806  0.101392  0.092159    0.993877      1  \n",
       "1523 -0.250085 -0.083285  0.508771  0.074280 -0.156735    0.726598      1  \n",
       "1524 -0.256581 -0.126499  0.109506 -0.313804 -0.241336  180.086978      1  \n",
       "1525 -1.083672 -0.742202  0.509854  0.034676  0.008290    1.272031      1  \n",
       "\n",
       "[1526 rows x 31 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled = pd.concat([pd.DataFrame(X_resampled,columns = X.columns),pd.DataFrame(Y_resampled,columns = ['Class'])],axis  = 1)\n",
    "df_resampled['Class'].value_counts()\n",
    "df_resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "14be4719",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    763\n",
       "1    763\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled.isnull().sum()\n",
    "df_resampled['Class'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e64098",
   "metadata": {},
   "source": [
    "Now Data is Balanced "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d1bbeb1",
   "metadata": {},
   "source": [
    "Models fitted on the balanced data sample \n",
    "\n",
    "1. Logistic Regression\n",
    "2. Decision Tree Classifier\n",
    "3. Random forest Classifer\n",
    "4. Gradient Boosting Classifier\n",
    "5. KNN Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db25211b",
   "metadata": {},
   "source": [
    "### Random Sampling \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "fb9da938",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = random_sample.drop('Class',axis = 1)\n",
    "y = random_sample['Class']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "effa1117",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    155\n",
       "0    145\n",
       "Name: Class, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Simple Random Sampling (SRS)\n",
    "random_sample = df_resampled.sample(n=300, random_state=1)\n",
    "random_sample = random_sample.reset_index(drop = True)\n",
    "# random_sample\n",
    "random_sample['Class'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "868f7cd0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-Nearest Neighbors...\n",
      "Accuracies for each model: [0.95, 0.9166666666666666, 1.0, 0.9333333333333333, 0.7166666666666667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "models = {\n",
    "    'Logistic Regression': LogisticRegression(),\n",
    "    'Decision Tree': DecisionTreeClassifier(),\n",
    "    'Random Forest': RandomForestClassifier(),\n",
    "    'Gradient Boosting': GradientBoostingClassifier(),\n",
    "    'K-Nearest Neighbors': KNeighborsClassifier()  # Replaced SVC with KNN\n",
    "}\n",
    "\n",
    "accuracies_srs = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies_srs.append(accuracy)\n",
    "print(\"Accuracies for each model:\", accuracies_srs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2df235e9",
   "metadata": {},
   "source": [
    "### Stratified Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "9937b8ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n",
      "Training Gradient Boosting...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training K-Nearest Neighbors...\n",
      "Accuracies for each model: [0.85, 0.9333333333333333, 0.9833333333333333, 0.9, 0.7666666666666667]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)\n",
    "\n",
    "accuracies_strat = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies_strat.append(accuracy)\n",
    "print(\"Accuracies for each model:\", accuracies_strat)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b902e35",
   "metadata": {},
   "source": [
    "### Systemic Sampling "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "1ec8475f",
   "metadata": {},
   "outputs": [],
   "source": [
    "step_size = 4\n",
    "data = df_resampled.iloc[::step_size]\n",
    "X = data.drop('Class',axis = 1)\n",
    "y = data['Class']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "d74037cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting...\n",
      "Training K-Nearest Neighbors...\n",
      "Accuracies for each model: [0.85, 0.9333333333333333, 0.9833333333333333, 0.9, 0.7666666666666667]\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "accuracies_sys = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies_sys.append(accuracy)\n",
    "print(\"Accuracies for each model:\", accuracies_sys)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "808afbb7",
   "metadata": {},
   "source": [
    "### Cluster Sampling\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "id": "c9068bb6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\cluster\\_kmeans.py:870: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "import random\n",
    "import numpy as np\n",
    "X = df_resampled.drop('Class',axis = 1)\n",
    "y = df_resampled['Class']\n",
    "clusters = 20\n",
    "kmeans = KMeans(n_clusters = clusters,random_state = 2)\n",
    "kmeans.fit(X)\n",
    "\n",
    "cluster_labels  = kmeans.labels_\n",
    "cluster_labels = cluster_labels.tolist()\n",
    "indexes = []\n",
    "random.seed = 42\n",
    "selected_clusters = random.sample(range(0,21),5)\n",
    "count = 0\n",
    "for i in cluster_labels:\n",
    "    if i in selected_clusters:\n",
    "        indexes.append(count)\n",
    "    count = count+1\n",
    "sample_cluster = df_resampled.iloc[indexes]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "f200b4c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting...\n",
      "Training K-Nearest Neighbors...\n",
      "Accuracies for each model: [0.9117647058823529, 0.9738562091503268, 0.9934640522875817, 0.9901960784313726, 0.8529411764705882]\n"
     ]
    }
   ],
   "source": [
    "X = sample_cluster.drop('Class',axis = 1)\n",
    "y = sample_cluster['Class']\n",
    "accuracies_cluster = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies_cluster.append(accuracy)\n",
    "print(\"Accuracies for each model:\", accuracies_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c56e429e",
   "metadata": {},
   "source": [
    "### Convenience Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "id": "b04eaa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Time        V1        V2        V3        V4        V5        V6  \\\n",
      "0       0 -1.359807 -0.072781  2.536347  1.378155 -0.338321  0.462388   \n",
      "1       0  1.191857  0.266151  0.166480  0.448154  0.060018 -0.082361   \n",
      "2       1 -1.358354 -1.340163  1.773209  0.379780 -0.503198  1.800499   \n",
      "3       1 -0.966272 -0.185226  1.792993 -0.863291 -0.010309  1.247203   \n",
      "4       2 -1.158233  0.877737  1.548718  0.403034 -0.407193  0.095921   \n",
      "..    ...       ...       ...       ...       ...       ...       ...   \n",
      "295   210  1.293927  0.338071 -0.042759  0.502134  0.072283 -0.583458   \n",
      "296   211  0.263523 -1.812897 -0.311087  0.412930 -0.794605  0.196365   \n",
      "297   211 -0.247827 -0.282682  1.653354 -1.014865 -0.680433  0.886364   \n",
      "298   213 -0.263380  0.959103  0.285740  0.604068  3.228820  3.799503   \n",
      "299   215  1.087792 -0.143548  1.374291  1.287399 -1.100642 -0.017110   \n",
      "\n",
      "           V7        V8        V9  ...       V21       V22       V23  \\\n",
      "0    0.239599  0.098698  0.363787  ... -0.018307  0.277838 -0.110474   \n",
      "1   -0.078803  0.085102 -0.255425  ... -0.225775 -0.638672  0.101288   \n",
      "2    0.791461  0.247676 -1.514654  ...  0.247998  0.771679  0.909412   \n",
      "3    0.237609  0.377436 -1.387024  ... -0.108300  0.005274 -0.190321   \n",
      "4    0.592941 -0.270533  0.817739  ... -0.009431  0.798278 -0.137458   \n",
      "..        ...       ...       ...  ...       ...       ...       ...   \n",
      "295  0.123779 -0.187468  0.001883  ... -0.329233 -0.942139  0.008264   \n",
      "296  0.416626 -0.062991  0.345392  ...  0.002672 -1.042342 -0.480538   \n",
      "297 -0.538201  0.377970 -1.230879  ...  0.545696  1.400962 -0.133992   \n",
      "298  0.715285  0.429148 -1.155492  ... -0.015245  0.059111 -0.291825   \n",
      "299 -0.705609  0.266580  0.735368  ... -0.003904  0.112285  0.014104   \n",
      "\n",
      "          V24       V25       V26       V27       V28  Amount  Class  \n",
      "0    0.066928  0.128539 -0.189115  0.133558 -0.021053  149.62      0  \n",
      "1   -0.339846  0.167170  0.125895 -0.008983  0.014724    2.69      1  \n",
      "2   -0.689281 -0.327642 -0.139097 -0.055353 -0.059752  378.66      0  \n",
      "3   -1.175575  0.647376 -0.221929  0.062723  0.061458  123.50      0  \n",
      "4    0.141267 -0.206010  0.502292  0.219422  0.215153   69.99      0  \n",
      "..        ...       ...       ...       ...       ...     ...    ...  \n",
      "295 -0.492104  0.342975  0.143926 -0.022441  0.025373   12.99      0  \n",
      "296 -0.414743  0.111706  0.819590 -0.168906  0.078203  526.96      0  \n",
      "297 -0.810782 -0.348544  0.093031  0.165626  0.130422   70.00      0  \n",
      "298  0.992903 -0.128938 -0.111063 -0.340206 -0.310297    4.38      0  \n",
      "299  0.512268  0.329602 -0.436531  0.063250  0.029067   12.99      0  \n",
      "\n",
      "[300 rows x 31 columns]\n"
     ]
    }
   ],
   "source": [
    "convenience_samples = df_resampled.head(300)\n",
    "print(convenience_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "id": "43be542c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Logistic Regression...\n",
      "Training Decision Tree...\n",
      "Training Random Forest...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Pratham\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Gradient Boosting...\n",
      "Training K-Nearest Neighbors...\n",
      "Accuracies for each model: [0.9117647058823529, 0.9803921568627451, 0.9934640522875817, 0.9901960784313726, 0.8529411764705882]\n"
     ]
    }
   ],
   "source": [
    "X = convenience_samples.drop('Class',axis = 1)\n",
    "y = convenience_samples['Class']\n",
    "accuracies_con = []\n",
    "for model_name, model in models.items():\n",
    "    print(f\"Training {model_name}...\")\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    accuracies_con.append(accuracy)\n",
    "print(\"Accuracies for each model:\", accuracies_con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "id": "5591468a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Random Sampling  Stratified Sampling  \\\n",
      "Logistic Regression         0.950000             0.850000   \n",
      "Decision Tree               0.916667             0.933333   \n",
      "Random Forest               1.000000             0.983333   \n",
      "Gradient Boosting           0.933333             0.900000   \n",
      "KNN                         0.716667             0.766667   \n",
      "\n",
      "                     Systematic Sampling  Cluster Sampling  \\\n",
      "Logistic Regression             0.911765          0.911765   \n",
      "Decision Tree                   0.977124          0.973856   \n",
      "Random Forest                   0.993464          0.993464   \n",
      "Gradient Boosting               0.990196          0.990196   \n",
      "KNN                             0.852941          0.852941   \n",
      "\n",
      "                     Convenience Sampling  \n",
      "Logistic Regression              0.911765  \n",
      "Decision Tree                    0.980392  \n",
      "Random Forest                    0.993464  \n",
      "Gradient Boosting                0.990196  \n",
      "KNN                              0.852941  \n"
     ]
    }
   ],
   "source": [
    "results= {'Random Sampling':accuracies_srs,\n",
    "                'Stratified Sampling':accuracies_strat,\n",
    "                'Systematic Sampling':accuracies_sys,\n",
    "                'Cluster Sampling':accuracies_cluster,\n",
    "                'Convenience Sampling':accuracies_con}\n",
    "results = pd.DataFrame(results,index = ['Logistic Regression','Decision Tree','Random Forest','Gradient Boosting','KNN'])\n",
    "print(results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
